{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Установка библиотек и импорты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install openpyxl pandas numpy sklearn matplotlib seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pandas.plotting import scatter_matrix\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import cross_validate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Загрузка датасета"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загрузка x_bp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x_bp = pd.read_excel(io = \"./hw_data_composite/X_bp.xlsx\")\n",
    "x_bp = x_bp.astype({'Unnamed: 0':'int'})\n",
    "x_bp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загрузка x_nup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x_nup = pd.read_excel(io = \"./hw_data_composite/X_nup.xlsx\")\n",
    "x_nup = x_nup.astype({'Unnamed: 0':'int','Угол нашивки, град':'int'})\n",
    "x_nup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Объединение таблиц и удаление столбца-индекса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dataset = pd.merge(x_bp, x_nup, how='inner', on='Unnamed: 0')\n",
    "dataset = dataset.drop(labels = 'Unnamed: 0', axis = 1)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Разведочный анализ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Медианы по столбцам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset.median()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Средние значения по столбцам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Убираю угол нашивки для отрисовки графиков (неинформативный параметр, т.к. принимает всего  2 значения)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_without_angles = dataset.drop(axis = 1, labels = 'Угол нашивки, град')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Гистограммы распределения переменных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ds_without_angles.hist(figsize = (20, 20), bins = 20, color = 'green')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Диаграммы размаха (ящики с усами) по каждой переменной"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for col in ds_without_angles.columns:\n",
    "    sns.boxplot(x = dataset[col], color = 'green')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Попарные диаграммы рассеяния"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pair_diagram = scatter_matrix(ds_without_angles, figsize = (16, 16), alpha = 0.25, color = 'green', diagonal = None)\n",
    "for ax in pair_diagram.ravel():\n",
    "    ax.set_xlabel(ax.get_xlabel(), fontsize = 10, rotation = 45)\n",
    "    ax.set_ylabel(ax.get_ylabel(), fontsize = 10, rotation = 45)\n",
    "pair_diagram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Предобработка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Проверка наличия пропусков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Поиск выбросов с помощью многомерного LocalOutlierFactor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "lof = LocalOutlierFactor(n_neighbors = 300)\n",
    "lof_pred = lof.fit_predict(ds_without_angles)\n",
    "outlier_indexes = []\n",
    "for i in range(len(lof_pred)):\n",
    "    if lof_pred[i] == -1:\n",
    "        outlier_indexes.append(i)\n",
    "print('Кол-во выбросов: ' + str(len(outlier_indexes)))\n",
    "dataset.loc[outlier_indexes]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Удаление выбросов из датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset.drop(outlier_indexes, inplace = True, errors='ignore')\n",
    "ds_without_angles.drop(outlier_indexes, inplace = True, errors='ignore')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Разделение датасета на входные и выходные параметры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset_inputs = dataset.drop(axis = 1,\n",
    "                              labels = ['Соотношение матрица-наполнитель',\n",
    "                                        'Модуль упругости при растяжении, ГПа',\n",
    "                                        'Прочность при растяжении, МПа'])\n",
    "dataset_output_mod_up = pd.DataFrame(dataset['Модуль упругости при растяжении, ГПа'])\n",
    "dataset_output_mat_nap = pd.DataFrame(dataset['Соотношение матрица-наполнитель'])\n",
    "dataset_output_str = pd.DataFrame(dataset['Прочность при растяжении, МПа'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Метод для scaling'а"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale(scaler, df):\n",
    "    scaler.fit(df)\n",
    "    df_scaled = pd.DataFrame(scaler.transform(df.values))\n",
    "    df_scaled.columns = df.columns\n",
    "    return scaler, df_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Нормализация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "min_max_scaler_inputs, dataset_inputs_normalized = scale(scaler = preprocessing.MinMaxScaler(),\n",
    "                                                         df = dataset_inputs)\n",
    "dataset_inputs_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_max_scaler_output_mod_up, dataset_output_mod_up_normalized = scale(scaler = preprocessing.MinMaxScaler(),\n",
    "                                                                       df = dataset_output_mod_up)\n",
    "min_max_scaler_output_mat_nap, dataset_output_mat_nap_normalized = scale(scaler = preprocessing.MinMaxScaler(),\n",
    "                                                                         df = dataset_output_mat_nap)\n",
    "min_max_scaler_output_str, dataset_output_str_normalized = scale(scaler = preprocessing.MinMaxScaler(),\n",
    "                                                      df = dataset_output_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Стандартизация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "standard_scaler_inputs, dataset_inputs_standartized = scale(scaler = preprocessing.StandardScaler(),\n",
    "                                                         df = dataset_inputs)\n",
    "dataset_inputs_standartized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "standard_scaler_output_mod_up, dataset_output_mod_up_standartized = scale(scaler = preprocessing.StandardScaler(),\n",
    "                                                                       df = dataset_output_mod_up)\n",
    "standard_scaler_output_mat_nap, dataset_output_mat_nap_standartized = scale(scaler = preprocessing.StandardScaler(),\n",
    "                                                                         df = dataset_output_mat_nap)\n",
    "standard_scaler_output_str, dataset_output_str_standartized = scale(scaler = preprocessing.StandardScaler(),\n",
    "                                                      df = dataset_output_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Построение моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подбор гиперпараметров по сетке с кросс валидацией по метрике R2 и обучение на лучших параметрах"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ридж-регрессия "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Прогноз модуля упругости при растяжении на нормализованном датасете"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_ridge(x, y, alphas = np.logspace(-10, -0, 11),\n",
    "                    n_splits = 10, scoring = None):\n",
    "    ridge_results = []\n",
    "    for alpha in alphas:\n",
    "        ridge_result = cross_val_score(\n",
    "            Ridge(alpha), x, y, cv=KFold(n_splits, shuffle = True), n_jobs = -1, scoring = scoring)\n",
    "        ridge_results.append([alpha, ridge_result.mean()])\n",
    "    ridge_df = pd.DataFrame(ridge_results, columns = ['alpha','score'])\n",
    "    return ridge_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_ridge_model(ridge_cross_val_res, dataset_inputs, dataset_output,\n",
    "                     output_scaler, test_size=0.3):\n",
    "    alpha_best = ridge_cross_val_res.sort_values(by = 'score',ascending = False)['alpha'].iloc[0]\n",
    "    print('Best alpha: ' + str(alpha_best))\n",
    "    \n",
    "    ridge_model = Ridge(alpha_best)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        dataset_inputs_normalized, dataset_output_mod_up_normalized, test_size=test_size)\n",
    "    ridge_model.fit(X_train, y_train)\n",
    "    \n",
    "    comparison_df = pd.DataFrame(np.column_stack(\n",
    "    [output_scaler.inverse_transform(ridge_model.predict(X_test)),\n",
    "     output_scaler.inverse_transform(y_test)]), columns=['Предсказанные данные', 'Тестовые данные'])\n",
    "    \n",
    "    print(comparison_df)\n",
    "    print('Средняя абсолютная ошибка: ' + str(mean_absolute_error(comparison_df['Тестовые данные'], comparison_df['Предсказанные данные'])))\n",
    "\n",
    "    return ridge_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Прогноз модуля упругости при растяжении на нормализованном датасете"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_mod_up_cross_val_res_normalized = calculate_ridge(dataset_inputs_normalized, dataset_output_mod_up_normalized)\n",
    "ridge_mod_up_cross_val_res_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_mod_up_best_normalized = make_ridge_model(ridge_mod_up_cross_val_res_normalized, dataset_inputs_normalized,\n",
    "                                                dataset_output_mod_up_normalized, min_max_scaler_output_mod_up)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Прогноз прочности при растяжении на нормализованном датасете"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_str_cross_val_res_normalized = calculate_ridge(dataset_inputs_normalized,dataset_output_str_normalized)\n",
    "ridge_str_cross_val_res_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_str_best_normalized = make_ridge_model(ridge_str_cross_val_res_normalized, dataset_inputs_normalized,\n",
    "                                             dataset_output_str_normalized, min_max_scaler_output_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Прогноз модуля упругости при растяжении на стандартизированном датасете"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_mod_up_cross_val_res_standartized = calculate_ridge(dataset_inputs_standartized, dataset_output_mod_up_standartized)\n",
    "ridge_mod_up_cross_val_res_standartized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_mod_up_best_standartized = make_ridge_model(ridge_mod_up_cross_val_res_standartized, dataset_inputs_standartized,\n",
    "                                                  dataset_output_mod_up_standartized, min_max_scaler_output_mod_up)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Прогноз прочности при растяжении на стандартизированном датасете"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_str_cross_val_res_standartized = calculate_ridge(dataset_inputs_standartized, dataset_output_str_standartized)\n",
    "ridge_str_cross_val_res_standartized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_str_best_standartized = make_ridge_model(ridge_str_cross_val_res_standartized, dataset_inputs_standartized,\n",
    "                                               dataset_output_str_standartized, min_max_scaler_output_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ElasticNet регрессия с полиномиальными параметрами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_elastic(x, y, alphas = np.logspace(-10, -0, 11), ratios = np.arange(11)/10,\n",
    "                      n_splits = 10, scoring = None):\n",
    "    poly_elastic_results = []\n",
    "    poly_x = PolynomialFeatures().fit_transform(x)\n",
    "    for alpha in alphas:\n",
    "        for ratio in ratios:    \n",
    "            poly_elastic_result = cross_val_score(\n",
    "                ElasticNet(alpha, l1_ratio = ratio),\n",
    "                poly_x, y, n_jobs=-1,\n",
    "                cv=KFold(n_splits, shuffle = True))\n",
    "            poly_elastic_results.append([alpha, ratio, poly_elastic_result.mean()])\n",
    "    elastic_df = pd.DataFrame(poly_elastic_results, columns = ['alpha','ratio','score'])\n",
    "    return elastic_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_elastic_model(elastic_cross_val_res, dataset_inputs, dataset_output,\n",
    "                       output_scaler, test_size=0.3):\n",
    "    elastic_cross_val_res = elastic_cross_val_res.sort_values(by = 'score',ascending = False)['alpha']\n",
    "    alpha_best = elastic_cross_val_res['alpha'].iloc[0]\n",
    "    print('Best alpha: ' + str(alpha_best))\n",
    "    ratio_best = elastic_cross_val_res['ratio'].iloc[0]\n",
    "    print('Best ratio: ' + str(ratio_best))\n",
    "    \n",
    "    elastic_model = ElasticNet(alpha = alpha_best, ratio = ratio_best)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        dataset_inputs_normalized, dataset_output_mod_up_normalized, test_size=test_size)\n",
    "    poly_x_train = PolynomialFeatures().fit_transform(X_train)\n",
    "    poly_x_test = PolynomialFeatures().fit_transform(X_test)\n",
    "    elastic_model.fit(poly_x_train, y_train)\n",
    "    \n",
    "    comparison_df = pd.DataFrame(np.column_stack(\n",
    "    [output_scaler.inverse_transform(elastic_model.predict(poly_x_test)),\n",
    "     output_scaler.inverse_transform(y_test)]), columns=['Предсказанные данные', 'Тестовые данные'])\n",
    "    \n",
    "    print(comparison_df)\n",
    "    print('Средняя абсолютная ошибка: ' + str(mean_absolute_error(comparison_df['Тестовые данные'], comparison_df['Предсказанные данные'])))\n",
    "\n",
    "    return elastic_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elastic_mod_up_cross_val_res_normalized = calculate_elastic(dataset_inputs_normalized, dataset_output_mod_up_normalized)\n",
    "elastic_mod_up_cross_val_res_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elastic_mod_up_best_normalized = make_elastic_model(elastic_mod_up_cross_val_res_normalized, dataset_inputs_normalized,\n",
    "                                                dataset_output_mod_up_normalized, min_max_scaler_output_mod_up)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_results = []\n",
    "for alpha in np.logspace(-10, -0, 11):\n",
    "    ridge_result = cross_val_score(\n",
    "        Ridge(alpha), input_data, output_data, cv=KFold(n_splits = 10, shuffle = True), n_jobs=-1)\n",
    "    ridge_results.append([alpha, ridge_result.mean()])\n",
    "ridge_df = pd.DataFrame(ridge_results, columns = ['alpha','score']).sort_values(by = 'score', ascending = False)\n",
    "ridge_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_results = []\n",
    "for alpha in np.logspace(-10, -0, 11):\n",
    "    lasso_result = cross_val_score(\n",
    "        Lasso(alpha), input_data, output_data, cv=KFold(n_splits = 10, shuffle = True), n_jobs=-1)\n",
    "    lasso_results.append([alpha, lasso_result.mean()])\n",
    "lasso_df = pd.DataFrame(lasso_results, columns = ['alpha','score']).sort_values(by = 'score', ascending = False)\n",
    "lasso_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_elastic_results = []\n",
    "for alpha in np.logspace(-10, -0, 11):\n",
    "    for ratio in np.arange(11)/10:    \n",
    "        poly_elastic_result = cross_val_score(\n",
    "            ElasticNet(alpha, l1_ratio = ratio),\n",
    "            PolynomialFeatures(2).fit_transform(input_data),\n",
    "            output_data,\n",
    "            cv=KFold(n_splits = 10, shuffle = True), n_jobs=-1)\n",
    "        poly_elastic_results.append([alpha, ratio, poly_elastic_result.mean()])\n",
    "pedf = pd.DataFrame(poly_elastic_results, columns = ['alpha','ratio','score']).sort_values(by = 'score', ascending = False)\n",
    "pedf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_train, input_test, out_train, out_test = train_test_split(\n",
    "    input_data, output_data, shuffle = True, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linr = LinearRegression(n_jobs = -1)\n",
    "linr.fit(input_train, out_train)\n",
    "print(lr.score(input_test, out_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridr = Ridge(alpha = ridge_df['alpha'].iloc[0])\n",
    "ridr.fit(input_train, out_train)\n",
    "print(ridr.score(input_test, out_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasr = Lasso(alpha = lasso_df['alpha'].iloc[0])\n",
    "lasr.fit(input_train, out_train)\n",
    "print(lasr.score(input_test, out_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "per = ElasticNet(alpha = pedf['alpha'].iloc[0], l1_ratio = pedf['ratio'].iloc[0])\n",
    "per.fit(PolynomialFeatures(2).fit_transform(input_train), out_train)\n",
    "print(per.score(PolynomialFeatures(2).fit_transform(input_test), out_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
